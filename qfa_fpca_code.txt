#================================================================================
#
# R code for Quantile-Frequency Analysis (QFA):
#   - compute quantile periodograms for time series data (multicore parellelization)
#   - compute semi-parametric quantile spectral estimates (multicore parellelization)
#   - compute functional principal component analysis (FPCA) on quntile periodograms
#   - classification of time series based on QFA-FPCA features (currently using classifiers LDA, QDA, and SVM)
#  
# Author: Ta-Hsin Li (thl@us.ibm.com)    10/20/2019
#
# References:
#   Li, T.-H. (2008) Laplace periodogram for time series analysis, Journal of the American Statistical Association, 103(482): 757--768.
#   Li, T.-H. (2012) Quantile periodogram, Journal of the American Statistical Association, 103(482): 757--768.
#   Chen, T., Sun, Y., and Li, T.-H. (2019) A semiparametric estimation algorithm for the quantile spectrum with an application
#      to earthquake classification using convolutional neural network, arXiv:1910.07155.
#   Li, T.-H. (2019) From zero crossings to quantile-frequency analysis of time series with an application 
#      to nondestructive evaluation, revised for Applied Stochastic Models in Business and Industry.
#
# NDE data "1mm_bond.sig" and "1mm_disbond.sig" available at https://www.math.umd.edu/~bnk/DATA/
#
#=================================================================================

# -- import data --

dir.d<-""
files<-c("1mm_bond.sig","1mm_disbond.sig")

labels<-c("B","D")     # two classes of time series
ms<-c(324,384)         # number of samples for each class
ns<-c(258,258)         # length of each time series in each class

nc<-length(labels)     # number of classes

data<-list()
for(k in c(1:nc)) {
  label<-labels[k]
  m<-ms[k]
  n<-ns[k]
  filename<-files[k]
  xx <- scan(paste(dir.d,filename,sep=""))
  xx<-xx[-c(1,2)]
  xx<-matrix(xx,nrow=n*2+1)
  xx<-xx[-1,]
  xx<-matrix(xx,ncol=2,byrow=T)
  xx<-xx[,2]
  xx<-matrix(xx,nrow=n)
  xx<-apply(xx,2,function(x) { (x - mean(x))/sd(x) })
  data[[k]]<-xx
  rm(xx)
}

# -- compute periodogram --

data.per<-list()
data.freq<-list()
for(k in c(1:nc)) {
  xx<-data[[k]]
  m<-ncol(xx)
  n<-nrow(xx)
  freq<-freq<-c(1:(n-1))/n
  freq<-freq[freq < 0.5]
  per<-matrix(0,ncol=m,nrow=length(freq))
  for(i in c(1:m)) {
    per[,i]<-gau.per(xx[,i],freq)
  }
  data.per[[k]]<-per
  data.freq[[k]]<-freq
  rm(xx,per,freq)
}


# -- compute ar fit of periodogram  --

data.per.ar<-list()
data.per.ar.order<-list()
for(k in c(1:nc)) {
  xx<-data[[k]]
  freq<-data.freq[[k]]
  per<-data.per[[k]]
  m<-ncol(xx)
  order.max<-floor(length(freq)/2)
  ord.ar<-rep(NA,m)
  per.ar<-per
  for(i in c(1:m)) {
    # yule-walker with aic 
    fit <- ar(xx[,i],order.max=order.max)
    ord.ar[i] <- fit$order
    per.ar[,i]<-ar.spec(fit,freq,log.scale=F)$spec
  }
  data.per.ar[[k]]<-per.ar
  data.per.ar.order[[k]]<-ord.ar
  rm(xx,freq,per,per.ar,ord.ar)
}


# -- compute quantile periodogram --

n.cores<-4                # number of cores
tau<-seq(0.06,0.94,0.02)  # grid points of quantile levels

data.qper<-list()
for(k in c(1:nc)) {
  xx<-data[[k]]
  freq<-data.freq[[k]]
  m<-ncol(xx)
  qper<-array(NA,dim=c(m,dim=c(length(freq),length(tau))))
  for(i in c(1:m)) {
    qper[i,,]<-lap.spec(xx[,i],freq,tau,n.cores=n.cores)
  }
  data.qper[[k]]<-qper
  rm(xx,freq,qper)
}


# -- compute ar fit of quantile periodogram --


if(n.cores>1) {
  library(foreach) 
  library(doParallel) # libraries required for parallel computing
  fit.cl <- makeCluster(n.cores)
  funs2export<-c("qper.ar.fit","lap.spec","spec.padding","order.select.qacf","qacf2spec","pacf2spec",
      "pacf2ar","pacf.smu","scale.smu","spec.supsmu","spec.smooth.spline","arspec","acf2ar","pacf2ar","rq")
  clusterExport(fit.cl,funs2export)
  registerDoParallel(fit.cl) 
}

data.qper.ar<-list()
for(k in c(1:nc)) {
  label<-labels[k]
  xx<-data[[k]]
  qper<-data.qper[[k]]
  m<-ms[k]
  freq<-data.freq[[k]]
  order.max<-floor(length(freq)/2)
  qper.list<-list()
  for(i in c(1:m)) qper.list[[i]]<-list(x=xx[,i],qper=qper[i,,])
  ptm <- proc.time()
  tmp<-parLapply(fit.cl,qper.list,qper.ar.fit.parallel,freq=freq,tau=tau)
  proc.time()-ptm
  qper.ar<-qper
  for(i in c(1:length(tmp))) qper.ar[i,,] <- tmp[[i]]$ar.spec
  rm(tmp,qper.list)
  data.qper.ar[[k]]<-qper.ar
  rm(xx,qper,qper.ar)
}

if(n.cores>1) stopCluster(fit.cl)


# -- classification based on FPCA of quantile periodogram --

# create data matrix for pca: cases x attributes
pca.data<-NULL
for(k in c(1:nc)) pca.data<-rbind(pca.data,t(qper2vec(data.qper[[k]])))

# create label vector
pca.labels<-NULL
for(k in c(1:nc)) pca.labels<-c(pca.labels,rep(k,dim(data.qper[[k]])[1]))

# split pca.data in to train and test
idx.train<-sample(c(1:nrow(pca.data)),ceiling(0.7*nrow(pca.data)))

# train pca
pca<-pca.train(pca.data[idx.train,])

# get pca features for train
features.train<-get.pca.features(pca,pca.data[idx.train,])
# get labels for train
labels.train<-pca.labels[idx.train]

# train classifiers
data.train<-data.frame(y=labels.train,x=features.train)
fit<-classification.train(data.train,meths)
fit$accuracy

# get pca features for test
features.test<-get.pca.features(pca,pca.data[-idx.train,])
# get labels for test
labels.test<-pca.labels[-idx.train]

# score test data
data.test<-data.frame(y=labels.test,x=features.test)
result<-classification.predict(fit,data.test)
result$accuracy


##=================================================================================


qper.ar.fit.parallel<-function(obj,freq,tau,type=2,intercept=T,
  ord=NULL,aic=T,aic.form="aic",ar.spec.freq=freq,eps=0.005,
  pacf.smooth=T,pacf.smooth.method='supsmu',pacf.bass=0,pacf.df=NULL,pacf.cv=F,
  scale.smooth=T,scale.smooth.method='supsmu',scale.bass=0,scale.df=NULL,scale.cv=F) {
  x<-obj$x
  qper<-obj$qper
  fit <- qper.ar.fit(x,qper,freq,tau,type,intercept,ord,aic,aic.form,ar.spec.freq,eps,
            pacf.smooth,pacf.smooth.method,pacf.bass,pacf.df,pacf.cv,
            scale.smooth,scale.smooth.method,scale.bass,scale.df,scale.cv)
  fit
}


qper.ar.fit<-function(x,qper,freq,tau,type=2,intercept=T,
  ord=NULL,aic=T,aic.form=c("aic","bic","aicc","arfit"),ar.spec.freq=freq,eps=0.005,
  pacf.smooth=F,pacf.smooth.method=c('supsmu','smooth.spline'),pacf.bass=0,pacf.df=NULL,pacf.cv=F,
  scale.smooth=F,scale.smooth.method=c('supsmu','smooth.spline'),scale.bass=0,scale.df=NULL,scale.cv=F,n.cores=1) {
# compute Yule-Walker AR coefficients from quantile periodogram
# x = time series
# qper = quantile periodograms at all Fourier frequencies in (0,0.5)
# n = length of time series
# freq = all Fourier frequencies in (0,0.5)
# tau = quantile levels
# ord = order of AR model
# if aic=T and lpc.ord=T, then order is selected from LCP
# aic.form = c("aic","bic","aicc")
# qper.offset = add percent of mean qper

  n <- length(x)
  if(n %% 2 == 0) {
      qper0<-lap.spec(x,0.5,tau=tau,intercept=intercept,type=type)
      if(length(tau)==1) { 
        qperl <- c(qper,qper0,rev(qper))
        qperl <- spec.padding(qperl,eps)
        qperl<-c(0,qperl)
      } else {
        qperl<-apply(qper,2,rev)
        qperl<-rbind(qper,qper0,qperl)
        qperl<-apply(qperl,2,spec.padding,eps=eps)
        qperl<-rbind(rep(0,length(tau)),qperl)
      }
  } else {
      if(length(tau)==1) {
        qperl <- c(qper,rev(qper))
        qperl <- spec.padding(qperl,eps)
        qperl<-c(0,qperl)
      } else {
        qperl<-apply(qper,2,rev)
        qperl<-rbind(qper,qperl)
        qperl<-apply(qperl,2,spec.padding,eps=eps)
        qperl<-rbind(rep(0,length(tau)),qperl)
      }
  }

  if(length(tau)==1) qperl<-matrix(qperl,ncol=1) 
  qacf<-Re(apply(qperl,2,fft,inverse=T)/n)
  if(length(tau)==1) qacf<-matrix(qacf,ncol=1)

  out<-NULL
  out$qacf<-qacf
  out$qperl<-qperl
  if(aic) {
    order.max<-ord
    if(aic.form[1] != "arfit") {
      out<-order.select.qacf(qacf,aic.form,order.max,pacf.smooth,pacf.smooth.method,pacf.bass,pacf.df,pacf.cv,n.cores)
      gic.mean<-apply(out$gic,1,function(y) { mean(y[y> -Inf]) } )
      # optimal order = minimizer of average gic across quantile levels
      ord<-rep(which.min(gic.mean)-1,length(tau))
      out$ord.mean<-ord
      out$ord<-ord
    } else {
     # same order for all levels from ar-aic fit of time series
      ord<-rep(ar(x,aic=T,order.max = order.max)$order,length(tau))
      out$ord<-ord
    }
    out$acf<-qacf
  } else {
    if(length(ord)==1) ord<-rep(ord,length(tau))
    out$ord<-ord
    out$gic<-NULL
  }

  if(aic & (aic.form[1] != "arfit")) {
    out$ar.spec<-pacf2spec(out$pacf,out$scale,ord,ar.spec.freq,pacf.smooth)
  } else {
    tmp<-qacf2spec(qacf,ord,ar.spec.freq,pacf.smooth,pacf.smooth.method,pacf.bass,pacf.df,pacf.cv)
    out$ar.spec<-tmp$spec
    out$scale<-tmp$scale
  }
   
  # - scale smoothing -
  if(scale.smooth) {
    out$scale.sm<-scale.smu(out$scale,scale.smooth.method,scale.bass,scale.df,scale.cv)
    for(j in c(1:length(tau))) { 
      if(out$scale[j] > 0) out$ar.spec[,j]<-out$scale.sm[j]*out$ar.spec[,j]/out$scale[j]
    }
  }
  
  out$ar.spec.freq<-ar.spec.freq
  out$aic.form<-aic.form
  out
}


pacf2ar<-function(phi) {
# Levinson Durbin to convert PACF to AR coefficients
# phi = ACF phi(1),...,phi(ord): can be complex numbers
 ord<-length(phi)
 if(ord>0) {
  a<-rep(0,ord)
  a.tmp<-a
  sig2<-a
  a[1] <- phi[1]
  sig2[1]<-(1.0-Mod(phi[1])^2)
  if(ord >= 2) {
    for(i in (2:ord)) {
      a[i]<-phi[i]
      sig2[i]<-sig2[i-1]*(1.0-Mod(phi[i])^2)
      for(j in (1:(i-1))) a.tmp[j]<-a[j]+phi[i]*Conj(a[i-j])
      a[1:(i-1)]<-a.tmp[1:(i-1)]
    }
  }
  out<-NULL
  out$ar<-a
  out$sig2<-c(1,sig2)
  out$pacf<-phi
 } else {
  out<-NULL
  out$ar<-0
  out$sig2<-1
  out$pacf<-0
 }
 out
}


acf2ar<-function(r,normalize=F) {
# Levinson Durbin for solving Yule-Walker equations R a = - r
# r = ACF r(0),...,r(ord): can be complex numbers
 ord<-length(r)-1
 if(ord>0 & Mod(r[1]) > 0.0) {
  a<-rep(0,ord)
  a.tmp<-a
  phi<-rep(0,ord)
  sig2<-a
  if(normalize) r <- r/r[1]
  r0<-Re(r[1])
  phi[1]<- -r[2]/r0
  a[1] <- phi[1]
  sig2[1]<-r0*(1.0-Mod(phi[1])^2)
  go<-T
  if(ord >= 2) {
    for(i in (2:ord)) {
      if(go) {
        phi[i]<- -(r[i+1]+sum(a[1:(i-1)]*rev(r[2:i])))/sig2[i-1]
        a[i]<-phi[i]
        sig2[i]<-sig2[i-1]*(1.0-Mod(phi[i])^2)
        if(sig2[i] <= 0.0) { 
          sig2[i:length(sig2)]<-sig2[i-1]
          phi[i] <- 0.0
          go<-F
        } else {
          for(j in (1:(i-1))) a.tmp[j]<-a[j]+phi[i]*Conj(a[i-j])
          a[1:(i-1)]<-a.tmp[1:(i-1)]
        }
      }
    }
  }
  out<-NULL
  out$ar<-a
  out$sig2<-c(r0,sig2)
  out$pacf<-phi
 } else {
  out<-NULL
  if(ord==0) {
    out$ar<-0
    if(normalize) {
      out$sig2<-1
    } else {
      out$sig2<-Re(r[1])
    }
    out$pacf<-0
  } else {
    out$ar<-rep(0,ord)
    if(normalize) {
      out$sig2<-rep(1,ord+1)
    } else {
      out$sig2<-rep(1,ord+1)
    }
    out$pacf<-rep(0,ord)
  }
 }
 out
}


order.select.qacf<-function(qacf,aic.form=c("aic","bic","aicc"),order.max=NULL,
  pacf.smooth=F,method=c('supsmu','smooth.spline'),bass=0,df=NULL,cv=F,n.cores=1) {
# order selection by gic from quantile ACF
# aic.form = c("aic","bic","aicc")

  n<-nrow(qacf)
  if(is.null(order.max)) order.max<-floor(n/4)
  nh <- order.max + 1
  if(n.cores==1) {
    ptm <- proc.time()
    tmp<-apply(matrix(qacf[1:nh,],ncol=ncol(qacf)),2,acf2ar,normalize=T)
    proc.time()-ptm
  } else {
    ptm <- proc.time()
    library(parallel) 
    cl <- makeCluster(n.cores)
    tmp<-parApply(cl,matrix(qacf[1:nh,],ncol=ncol(qacf)),2,acf2ar,normalize=T)
    stopCluster(cl)
    proc.time()-ptm
  }

  if(pacf.smooth) {
    tmp.pacf<-lapply(tmp,FUN=function(y) {y$pacf} )
    tmp.pacf<-matrix(unlist(tmp.pacf),ncol=length(tmp.pacf))
    tmp.pacf.sm<-pacf.smu(tmp.pacf,method,bass,df,cv)
    tmp<-list()
    for(i in c(1:ncol(tmp.pacf.sm))) tmp[[i]]<-tmp.pacf.sm[,i]
    tmp<-lapply(tmp,pacf2ar)
  }

  p<-c(0:(nh-1))
  if(aic.form[1]=="aic") tmp.gic<-lapply(tmp,FUN=function(y,p,n) { n*log(y$sig2)+2*p },p=p,n=n)
  if(aic.form[1]=="bic") tmp.gic<-lapply(tmp,FUN=function(y,p,n) { n*log(y$sig2)+log(n)*p },p=p,n=n)
  if(aic.form[1]=="aicc") tmp.gic<-lapply(tmp,FUN=function(y,p,n) { n*log(y$sig2)+2*p*n/(n-p-1) },p=p,n=n)
  tmp.gic<-matrix(unlist(tmp.gic),ncol=ncol(qacf))
  tmp.pacf<-matrix(unlist(lapply(tmp,FUN=function(y) { y$pacf })),ncol=ncol(qacf))
  tmp.ar<-matrix(unlist(lapply(tmp,FUN=function(y) { y$ar })),ncol=ncol(qacf))
  tmp.sig2<-matrix(unlist(lapply(tmp,FUN=function(y) { y$sig2 })),ncol=ncol(qacf))
  return(list(gic=tmp.gic,ar=tmp.ar,pacf=tmp.pacf,sig2=tmp.sig2,scale=qacf[1,]))
}


pacf.smu<-function(tmp.pacf,method=c('supsmu','smooth.spline'),bass=0,df=NULL,cv=F) {
  tmp.pacf.atanh<-atanh(tmp.pacf)
  if(method[1]=='smooth.spline') {
    if(is.null(df)) {
        tmp.pacf.atahn.sm<-t(apply(tmp.pacf.atanh,1,function(y) { smooth.spline(c(1:length(y)),y,all.knots=T,cv=cv)$y }))
    } else {
        tmp.pacf.atahn.sm<-t(apply(tmp.pacf.atanh,1,function(y) { smooth.spline(c(1:length(y)),y,,all.knots=T,df=df)$y }))
    }
  } else {
       tmp.pacf.atahn.sm<-t(apply(tmp.pacf.atanh,1,function(y) { supsmu(c(1:length(y)),y,bass=bass)$y }))
  }
  tmp.pacf.sm<-tanh(tmp.pacf.atahn.sm)
  tmp.pacf.sm
}


qacf2spec<-function(qacf,ord,ar.spec.freq,pacf.smooth=F,method=c('supsmu','smooth.spline'),bass=0,df=NULL,cv=F) {
  tmp<-list()
  if(pacf.smooth) {
    for(i in c(1:ncol(qacf))) tmp[[i]]<-qacf[1:(max(ord)+1),i]
  } else {
    for(i in c(1:ncol(qacf))) tmp[[i]]<-qacf[1:(ord[i]+1),i]
  }
  # levinson-durbin
  tmp<-lapply(tmp,acf2ar)
  if(pacf.smooth) {
    tmp.pacf<-lapply(tmp,FUN=function(y) {y$pacf} )
    tmp.pacf<-matrix(unlist(tmp.pacf),ncol=length(tmp.pacf))
    tmp.pacf.sm<-pacf.smu(tmp.pacf,method,bass,df,cv)
    tmp<-list()
    for(i in c(1:ncol(tmp.pacf.sm))) tmp[[i]]<-tmp.pacf.sm[,i]
    tmp<-lapply(tmp,pacf2ar)
  }
  tmp.ar<-lapply(tmp,FUN=function(y) { c(y$sig2[length(y$sig2)],y$ar) })
  tmp.spec<-lapply(tmp.ar,FUN=function(y,freq) { arspec(y[-1],y[1],2*pi*freq)},freq=ar.spec.freq)
  tmp.spec<-matrix(unlist(tmp.spec),ncol=length(tmp.ar))
  tmp.scale<-unlist(lapply(tmp.ar,FUN=function(y) { y[1] }))
  return(list(spec=tmp.spec,scale=tmp.scale))
}

pacf2spec<-function(tmp.pacf,tmp.scale,ord,ar.spec.freq,pacf.smooth=F) {
# construct ar spectrum from pacf
# tmp.pacf = pacf matrix 
  if(pacf.smooth) {
    tmp<-list()
    for(i in c(1:ncol(tmp.pacf))) tmp[[i]]<-tmp.pacf[1:max(ord),i]
  } else {
    tmp<-list()
    for(i in c(1:ncol(tmp.pacf))) tmp[[i]]<-tmp.pacf[1:ord[i],i]
  }
  # levinson-durbin
  tmp<-lapply(tmp,pacf2ar)
  # replace normlized sig2 with un-normalized sig2 (consistent with qact2ar)
  for(i in c(1:ncol(tmp.pacf))) tmp[[i]]$sig2<-tmp.scale[i]*tmp[[i]]$sig2
  tmp.ar<-lapply(tmp,FUN=function(y) { c(y$sig2[length(y$sig2)],y$ar) })
  tmp.spec<-lapply(tmp.ar,FUN=function(y,freq) { arspec(y[-1],y[1],2*pi*freq)},freq=ar.spec.freq)
  tmp.spec<-matrix(unlist(tmp.spec),ncol=length(tmp.ar))
  return(tmp.spec)
}

spec.padding<-function(y,eps=0.0) { 
    y + eps * mean(y)
}


scale.smu<-function(s,method=c('supsmu','smooth.spline'),bass=0,df=NULL,cv=F,eps=0.0) {
  if(method[1]=='smooth.spline') {
     s.sm<-spec.smooth.spline(c(1:length(s)),s,df=df,cv=cv,eps=eps)
  } else {
     s.sm<-spec.supsmu(c(1:length(s)),s,bass=bass,eps=eps)
  }
  s.sm
}


spec.supsmu<-function(x,y,bass=0,eps=0.0) {
# smooth periodogram in log domain using supsmu
  y.smu<-y
  y.smu<-spec.padding(y.smu,eps)
  idx<-which(y.smu > 0.0)
  if(length(idx)> 0) y.smu[idx]<-exp(supsmu(x[idx],log(y.smu[idx]),bass=bass)$y)
  if(length(idx) < length(y) & length(idx) > 0) y.smu<-approx(x[idx],y.smu[idx],xout=x,rule=)$y
  y.smu
}


spec.smooth.spline<-function(x,y,df=NULL,cv=F,eps=0.0) {
# smooth periodogram in log domain using smooth.spline
  y.smu<-spec.padding(y,eps)
  idx<-which(y.smu > 0.0)
  if(length(idx) > 0) { 
    if(is.null(df)) {
      # smoothness found GCV or CV
      y.smu[idx]<-exp(smooth.spline(x[idx],log(y.smu[idx]),all.knots=T,cv=cv)$y)
    } else {
      # smoothness controled by df
      y.smu[idx]<-exp(smooth.spline(x[idx],log(y.smu[idx]),all.knots=T,df=df)$y)
    }
  }
  if(length(idx) < length(y) & length(idx) > 0) y.smu<-approx(x[idx],y.smu[idx],xout=x,rule=2)$y
  y.smu
}


gau.spec<-function(y,f,intercept=T,type=2,weights=NULL,n.cores=1,exist.cores=F) {
# type 1: squared L2 norm of coefficients
# type 2: cost difference
 rsoid2<-function(n,f,a,b) {
  p<-length(f)
  tt<-c(1:n)
  one<-rep(1,n)
  tmp<-(one %o% a) * cos(2*pi*(tt %o% f)) + (one %o% b) * sin(2*pi*(tt %o% f))
  tmp<-apply(tmp,1,sum)
  tmp
 }

 gau.cost<-function(y,weights=NULL) {
    # cost function of LS regression
    ns<-length(y)
    if(is.null(weights)) weights<-rep(1,ns)
    sum(weights*y^2,na.rm=T)/2
 }

 gh.parallel<-function(yy,ff,tt,ns,weights,type) {
 # parallel computation of ls harmonic regression
 # for a single value of ff
 # used when intercept = F 
    if(ff==0.5) {
      fit<-glm(yy ~ 0+cos(2*pi*ff*tt),weights=weights)
      fit$coefficients<-c(fit$coefficients,0)
    }
    if(ff==0) {
      fit$coefficients<-c(mean(y),0)
    }
    if(ff != 0.5 & ff>0) {
      fit<-glm(yy ~ 0+cos(2*pi*ff*tt)+sin(2*pi*ff*tt),weights=weights)
    }
    fit$residuals<-yy-rsoid2(ns,ff,fit$coefficients[1],fit$coefficients[2])
    if(type==1) tmp.coef<-fit$coefficients
    if(type==2) tmp.cost<-gau.cost(fit$residuals,weights=weights)
    rm(fit)
    if(type==1) return(tmp.coef)
    if(type==2) return(tmp.cost)
 }

 gh.parallel2<-function(yy,ff,tt,ns,weights,type) {
 # parallel computation of ls harmonic regression
 # for a single value of ff
 # used when intercept = T
    if(ff==0.5) {
      fit<-glm(yy ~ cos(2*pi*ff*tt),weights=weights)
      fit$coefficients<-c(fit$coefficients,0)
    }
    if(ff==0) {
      fit$coefficients<-c(0,mean(yy),0)
    }
    if(ff != 0.5 & ff > 0) {
      fit<-glm(yy ~ cos(2*pi*ff*tt)+sin(2*pi*ff*tt),weights=weights)
    }
    fit$coefficients<-fit$coefficients
    if(type==1) {
       if(ff!=0.5) tmp.coef<-fit$coefficients[-1]
       if(ff==0.5) tmp.coef<-2*fit$coefficients[-1]
    }
    if(type==2) {
       tmp.resid<-yy-fit$coefficients[1]-rsoid2(ns,ff,fit$coefficients[2],fit$coefficients[3])
       tmp.cost<-gau.cost(tmp.resid,weights=weights); rm(tmp.resid)
    }
    rm(fit)
    if(type==1) return(tmp.coef)
    if(type==2) return(tmp.cost)
 }

 ns<-length(y)
 nf<-length(f)
 tt<-c(1:ns)

 if(n.cores>1 & exist.cores==F) {
  library(foreach) 
  library(doParallel) # libraries required for parallel computing
  classify.cl <- makeCluster(n.cores)
  registerDoParallel(classify.cl) 
 }

 if(is.null(weights)) weights<-rep(1,ns)
 yy<-y
 if(intercept) {
    if(type==1) coef<-matrix(NA,ncol=2,nrow=nf)
    if(type==2) { 
      cost<-rep(NA,nf)
      fit<-glm(yy ~ 1,weights=weights)
      cost0<-gau.cost(yy-fit$coefficients,weights=weights)
    }
    if(n.cores>1) {
  	  tmp<-foreach(i=1:nf) %dopar% { gh.parallel2(yy,f[i],tt,ns,weights,type) }
    } else {
      library(foreach)
  	  tmp<-foreach(i=1:nf) %do% { gh.parallel2(yy,f[i],tt,ns,weights,type) }
    }
    if(type==1) {
      out<-lapply(tmp,FUN=function(x) {apply(x^2,2,sum)})
      out<-c(unlist(out))
      out<-out*ns/4
    }
    if(type==2) {
      out<-c(unlist(tmp))
      out<-cost0-out
    }
  } else {
    if(type==1) coef<-matrix(NA,ncol=2,nrow=nf)
    if(type==2) yy<-y-mean(y,na.rm=T)
    cost0<-gau.cost(yy,weights=weights)
    if(n.cores>1) {
    	tmp<-foreach(i=1:nf) %dopar% { gh.parallel(yy,f[i],tt,ns,weights,type) }
    } else {
        library(foreach)
    	tmp<-foreach(i=1:nf) %do% { gh.parallel(yy,f[i],tt,ns,weights,type) }
    }
    if(type==1) {
        coef<-matrix(unlist(tmp),ncol=2,byrow=T)
        out<-apply(coef^2,1,sum)*ns/4
    }
    if(type==2) {
        cost<-c(unlist(tmp))
        out<-cost0-cost
    }
 }
 if(n.cores>1 & exist.cores==F) stopCluster(classify.cl)
 out[out<0]<-0
 out
}



lap.spec<-function(y,f,tau=0.5,intercept=T,type=2,weights=NULL,method="fn",n.cores=1,exist.cores=F) {
# type 1: squared L2 norm of coefficients
# type 2: cost difference

 rsoid2<-function(n,f,a,b) {
  p<-length(f)
  tt<-c(1:n)
  one<-rep(1,n)
  tmp<-(one %o% a) * cos(2*pi*(tt %o% f)) + (one %o% b) * sin(2*pi*(tt %o% f))
  tmp<-apply(tmp,1,sum)
  tmp
 }

 lap.cost<-function(y,tau=0.5,weights=NULL) {
 # cost function of quantile regression
   n<-length(y)
   if(is.null(weights)) weights<-rep(1,n)
   tmp<-tau*y
   sel<-which(y < 0)
   if(length(sel) > 0) tmp[sel]<-(tau-1)*y[sel]
   sum(tmp*weights,na.rm=T)
 }

 qh.parallel<-function(yy,ff,tau,tt,ns,weights,type) {
 # parallel computation of quantile harmonic regression
 # for a single value of tau (and single value of ff)
 # used when intercept = F
    if(ff==0.5) {
      fit<-try(rq(yy ~ 0+cos(2*pi*ff*tt),method=method,tau=tau,weights=weights),silent=T)
      if(length(fit)==1) {
        fit<-NULL
        fit$coefficients<-c(0,0)
      } else {
        fit$coefficients<-c(fit$coefficients,0)
      }
    }
    if(ff==0) {
      fit<-NULL
      fit$coefficients<-c(0,0)
    }
    if(ff != 0.5 & ff>0) {
      fit<-try(rq(yy ~ 0+cos(2*pi*ff*tt)+sin(2*pi*ff*tt),method=method,tau=tau,weights=weights),silent=T)
      if(length(fit)==1) {
        fit<-NULL
        fit$coefficients<-c(0,0)
      }
    }
    fit$residuals<-yy-rsoid2(ns,ff,fit$coefficients[1],fit$coefficients[2])
    if(type==1) tmp.coef<-fit$coefficients
    if(type==2) tmp.cost<-lap.cost(fit$residuals,tau=tau,weights=weights)
    rm(fit)
    if(type==1) return(tmp.coef)
    if(type==2) return(tmp.cost)
 }

 qh.parallel2<-function(yy,ff,tau,tt,ns,weights,type) {
 # parallel computation of quantile harmonic regression
 # for a vector of tau (and single value of ff)
 # used when intercept = T
    if(ff==0.5) {
      fit<-rq(yy ~ cos(2*pi*ff*tt),method=method,tau=tau,weights=weights)
      if(length(fit)==1) {
        fit<-NULL
        fit$coefficients<-rbind(quantile(yy,probs=tau),rep(0,length(tau)),rep(0,length(tau)))
      } else {
        fit$coefficients<-rbind(fit$coefficients,rep(0,length(tau)))
      }
    }
    if(ff==0) {
      fit<-NULL
      fit$coefficients<-rbind(quantile(yy,probs=tau),rep(0,length(tau)),rep(0,length(tau)))
    }
    if(ff != 0.5 & ff > 0) {
      fit<-try(rq(yy ~ cos(2*pi*ff*tt)+sin(2*pi*ff*tt),method=method,tau=tau,weights=weights),silent=T)
      if(length(fit)==1) {
        fit<-NULL
        fit$coefficients<-rbind(quantile(yy,probs=tau),rep(0,length(tau)),rep(0,length(tau)))
      }
    }
    fit$coefficients<-matrix(fit$coefficients,ncol=length(tau))
    if(type==1) {
       if(ff!=0.5) tmp.coef<-matrix(fit$coefficients[-1,],ncol=length(tau))
       if(ff==0.5) tmp.coef<-matrix(2*fit$coefficients[-1,],ncol=length(tau))
    }
    if(type==2) {
     if(length(tau)==1) fit$coefficients<-matrix(fit$coefficients,ncol=1)
     tmp.cost<-rep(NA,length(tau))
     for(i.tau in c(1:length(tau))) {
       tmp.resid<-yy-fit$coefficients[1,i.tau]-rsoid2(ns,ff,fit$coefficients[2,i.tau],fit$coefficients[3,i.tau])
       tmp.cost[i.tau]<-lap.cost(tmp.resid,tau=tau[i.tau],weights=weights)
     }
    rm(tmp.resid)
    }
    rm(fit)
    if(type==1) return(tmp.coef)
    if(type==2) return(tmp.cost)
 }

 ns<-length(y)
 nf<-length(f)
 tt<-c(1:ns)
 ntau<-length(tau)

 if(n.cores>1 & exist.cores==F) {
  library(foreach) 
  library(doParallel) # libraries required for parallel computing
  cl <- makeCluster(n.cores)
  clusterExport(cl, c("rq"))
  registerDoParallel(cl) 
 }

 if(is.null(weights)) weights<-rep(1,ns)

 yy<-y
 if(intercept) {
 
    if(type==1) coef<-array(NA,dim=c(ntau,2,nf))
    if(type==2) { 
      cost<-matrix(NA,ntau,nf)
      fit<-rq(yy ~ 1,method=method,tau=tau,weights=weights)
      if(ntau==1) fit$coefficients<-matrix(fit$coefficients,ncol=1)
      cost0<-rep(NA,ntau)
      for(i.tau in c(1:ntau)) cost0[i.tau]<-lap.cost(yy-fit$coefficients[,i.tau],tau=tau[i.tau],weights=weights)
    }

    if(n.cores>1) {
      tmp <- foreach(i=1:nf) %dopar% { qh.parallel2(yy,f[i],tau=tau,tt,ns,weights,type) }
    } else {
      library(foreach)
      tmp <- foreach(i=1:nf) %do% { qh.parallel2(yy,f[i],tau=tau,tt,ns,weights,type) }
    }
    if(type==1) {
      out<-lapply(tmp,FUN=function(x) {apply(x^2,2,sum)})
      out<-matrix(unlist(out),ncol=ntau,byrow=T)
      out<-out*ns/4
    }
    if(type==2) {
      out<-matrix(unlist(tmp),ncol=ntau,byrow=T)
      out<-matrix(rep(cost0,nf),ncol=ntau,byrow=T)-out
    }

  } else {

    out<-NULL
    for(i.tau in c(1:ntau)) {
      if(type==1) coef<-matrix(NA,ncol=2,nrow=nf)
      if(type==2) yy<-y-quantile(y,probs=tau[i.tau],na.rm=T)
      cost0<-lap.cost(yy,tau=tau[i.tau],weights=weights)
      if(n.cores>1) {
    	  tmp<-foreach(i=1:nf) %dopar% { qh.parallel(yy,f[i],tau=tau[i.tau],tt,ns,weights,type) }
      } else {
          library(foreach)
    	  tmp<-foreach(i=1:nf) %do% { qh.parallel(yy,f[i],tau=tau[i.tau],tt,ns,weights,type) }
      }
      if(type==1) {
        coef<-matrix(unlist(tmp),ncol=2,byrow=T)
        out<-cbind(out,apply(coef^2,1,sum)*ns/4)
      }
      if(type==2) {
        cost<-c(unlist(tmp))
        out<-cbind(out,cost0-cost)
      }
    }

 }

 if(n.cores>1 & exist.cores==F) stopCluster(cl)

 out[out<0]<-0
 if(ntau==1) out<-c(out)
 out

}


arspec<-function(phi,sig2,w) {
  p<-length(phi)
  al<-c(1,phi)
  j<-c(0:p) %o% w
  out<-sig2/Mod(apply(al*exp(-1i*j),2,sum))^2
  out
}



qper2vec<-function(data.qper,freqsel=NULL,tausel=NULL) {
# flattens array of 2d qpers into column vectors
  if(length(dim(data.qper))==3) {
    if(is.null(freqsel)) freqsel<-c(1:dim(data.qper)[2])
    if(is.null(tausel)) tausel<-c(1:dim(data.qper)[3])
    apply(data.qper[,freqsel,tausel],1,function(y) {c(y)})
  } else {
    if(is.null(freqsel)) freqsel<-c(1:dim(data.qper)[1])
    if(is.null(tausel)) tausel<-c(1:dim(data.qper)[2])
    c(data.qper[freqsel,tausel])
 }
}

pca.train<-function(data) {
# data = n-by-m matrix, where n = number of cases, m = number of attributes
  pca<-prcomp(data)
  pca
}

get.pca.features<-function(pca,data,pcsel=c(1:2)) {
# pca = output from pca.train
  features<-(data - pca$center) %*% pca$rotation[,pcsel]
  features
}

classification.train<-function(data.train,meths=c('lda','qda','svm')) {
##  allow multiple classifiers
##  data.train = data.frame(y=label,x=feature)
  fmla <- as.formula(paste("as.factor(y) ~ ",paste(colnames(data.train)[-1],collapse="+")))
  accuracy<-NULL
  fit<-list()
  for(i in c(1:length(meths))) {
    if(meths[i]=="qda") fit0<-try(qda(fmla, data = data.train),silent=T)  
    if(meths[i]=="lda") fit0<-try(lda(fmla, data = data.train),silent=T)
    if(meths[i]=="svm") fit0<-try(tune.svm(fmla,data = data.train,kernel='linear', cost = 10^(-3:2))$best.model,silent=T)
    fit[[i]]<-fit0
    tmp.accuracy<-NA
    if(length(fit0) > 1) {
      if(meths[i] == "svm") {
        pred<-predict(fit0,data.train)
      } else {
        pred<-predict(fit0,data.train)$class
      }
      true<-data.train[,1]
      tmp.accuracy<-mean(true == pred)
    }
    accuracy<-c(accuracy,tmp.accuracy)
  }
  return(list(fit=fit,accuracy=accuracy,meths=meths))
}


classification.predict<-function(fit.obj,data.new) {
# fit.obj = output from binary_classification_train
  pred<-NULL
  accuracy<-NULL
  for(i in c(1:length(fit.obj$meths))) {
    fit <- fit.obj$fit[[i]]
    tmp.pred<-rep(NA,nrow(data.new))
    if(length(fit) > 1) {
      if(fit.obj$meths[i] == 'svm') {
        tmp.pred<-predict(fit,newdata=data.new)
      } else {
        tmp.pred<-predict(fit,newdata=data.new)$class
      }
    }
    pred<-cbind(pred,tmp.pred)
    if(!is.null(data.new$y)) {
      tmp.accuracy = mean(tmp.pred == data.new$y)
      accuracy = c(accuracy,tmp.accuracy)
    }
 }
 colnames(pred)<-fit.obj$meths
 return(list(pred=pred,accuracy=accuracy))
}

